---
author:
- Александр Петров
date: 2023-01-04
title: Линейная алгебра для чайников
---

[]{#content label="content"}

## Информация о версиях

-   Учебник-1 $\rightarrow$ Учебник-2: Добавлена тема \"Ранг матрицы\"

-   Учебник-2 $\rightarrow$ Учебник-3: Добавлена тема \"Системы линейных
    алгебраических уравнений (СЛАУ)\" , изменён пункт 2.1.

-   Учебник-3 $\rightarrow$ Учебник-4: Добавлена тема \"Линейное
    пространство\"

-   Учебник-4 $\rightarrow$ Учебник-5: Добавлена тема \"Линейное
    отображение\" , добавлен пункт \"Summary\" в главе \"Линейное
    пространство\" , добавлен материал к вступлению главы \"Линейное
    пространство\"

# Предисловие

Вы открыли текст, в котором я попытался представить свой взгляд на
предмет \"Линейная алгебра\". В вузе мне преподавали его исходя из того,
что я знаю зачем пришёл на Физтех, что мне не нужно объяснять
необходимость тех абстракций, которые излагает лектор. Меня такой подход
не устраивал, и я задался вопросом - а зачем этот линал вообще нужен?
Вопрос \"зачем?\" ненаучный, потому что мотивация заниматься чем-либо у
каждого своя. Но из-за отсутствия каких-либо мнений вокруг мне пришлось
формировать своё самостоятельно, к чему и призываю читателя.

Я учусь на факультете аэромеханики и летательной техники МФТИ, поэтому и
ответы на вопросы \"зачем?\" будут соответствующими моей специальности,
но я всё же постараюсь учесть и другие мнения.

Научил меня задавать вопрос \"зачем?\" мой семинарист по общей физике
Серохвостов Сергей Владимирович, за что ему большое спасибо (за знания
по физике спасибо сказать не могу, к сожалению). В дальнейшем я развивал
своё видение вузовского образования, построенного вокруг вопроса
\"зачем?\" , в частности меня интересовало то, как должен быть построен
идеальный учебник по любому предмету. Пока что я не вывел рецепт
идеального учебника, но, кажется, я на верном пути. Этот текст я писал,
вдохновившись авторами лучшими учебных пособий, которые я имел счастье
открыть: Игорь Арнольд (Обыкновенные дифференциальные уравнения), Сергей
Гаврилов (Функциональный анализ для начинающих), Александр Львовский
(Отличная квантовая механика).

# Матрицы

# Обратная матрица

Матрица $B$ называется **обратной** к матрице $A$, если выполняются
равенства: $$BA = AB = E, \qquad \text{ где } E \text{ - единичная}$$
Обозначается обратная матрица так: $B = A^{-1}$. В чем мотивация вводить
обратную матрицу? Можно привести два примера:

Во первых, если знать (уметь находить) обратную матрицу, то можно
мгновенно находить решения системы линейных уравнений с невырожденной
матрицей системы: $$Ax = b \Rightarrow x = A^{-1}b$$

Во-вторых, если $A$ - матрица преобразования координат, например,
поворота на угол $\varphi$ вокруг оси $Oz$, то можно, зная координаты
вектора $\boldsymbol{x}'$ в новой СК найти его координаты в старой СК:
$$\boldsymbol{x} = \begin{pmatrix}
        x_1 \\
        x_2 \\
        x_3
    \end{pmatrix} = \begin{pmatrix}
        \text{cos } \varphi & \text{sin } \varphi & 0 \\
        -\text{sin } \varphi & \text{cos } \varphi & 0 \\
        0 & 0 & 1
    \end{pmatrix}^{-1} \begin{pmatrix}
        x_1' \\
        x_2' \\
        x_3'
    \end{pmatrix} = A^{-1}\boldsymbol{x}'$$

::: problem
**Задача 1**. Чему равна $A^{-1}$ в примере с поворотом? (не пользуйтесь
методом Гаусса)
:::

## Свойства обратных матриц

### Существование и единственность {#существование-и-единственность .unnumbered}

Первое, что нужно определить: у всех ли матриц существуют обратные? И
бывает ли у одной матрицы несколько обратных к ней?

Из определения видно, что обратимыми матрицами могут быть только
квадратные (посмотрите что происходит, если предположить, что не
квадратная матрица имеет обратную).

::: problem
**Задача 2**. Попробуйте исследовать вопрос единственности
самостоятельно. Предположите что обратная матрица не единственна, и
найдите противоречие, или докажите, что обратных матриц действительно
бывает несколько.
:::

### Обратные матрицы к $AB$ и $A^T$ {#обратные-матрицы-к-ab-и-at .unnumbered}

Для удобной работы с обратными матрицами вам понадобится знать как в
общем случае найти обратную матрицу от произведения известных матриц $A$
и $B$, а также обратную матрицу от транспонированной (в жизни мне это ни
разу не пригодилось, но вдруг вам пригодится).

Что значит найти $(AB)^{-1}$? Это значит, что нужно выразить эту матрицу
через $A^{-1}$ и $B^{-1}$.

::: problem
**Задача 3**. Найдите $(AB)^{-1}$ и $(A^T)^{-1}$. Честное слово, это
делается в одну строчку. (при нахождении обратной к транспонированной
вспомните как транспонировать произведение)
:::

::: problem
**Задача 4** (**Критерий существования обратной матрицы**). Обратная
матрица - серьезная штука, и нельзя просто так взять и начать находить
обратную матрицу. Надо быть уверенным, что она вообще существует.
Оказывается, что для обратимости матрицы необходимо и достаточно, чтобы
она была невырожденной.

Докажите этот факт (используйте интернет и навык гугления).
:::

## Как находить обратную матрицу? (Метод Гаусса)

Теперь перейдём к практике. Часто для нахождения обратной матрицы
используют метод Гаусса.

Суть его состоит в следующем: элементарными преобразованиями строк в
матрице $(A|E)$ мы сначала получаем из матрицы $A$ верхнетреугольную (с
ненулевыми элементами над главной диагональю) с единицами на главной
диагонали. Коротко это называется \"прямой ход метода Гаусса\"[^1]. А
затем производим элементарные преобразования строк, чтобы получить
единичную матрицу на месте матрицы $A$ - \"обратный ход метода Гаусса\".
При таких манипуляциях со строками на месте исходной единичной матрицы
появится искомая $A^{-1}$.

Или короче:
$$\fbox{\textit{Общий вид: } $(A|E) \xrightarrow{\text{ЭП Строк}} (E|A^{-1})$}$$

Для наглядности приведу пример:

::: ex
**Пример 1**. $$\underbrace{\begin{pmatrix}
                1 & 1 & 1 & 1 & 0 & 0 \\
                1 & 2 & 2 & 0 & 1 & 0 \\
                2 & 3 & 4 & 0 & 0 & 1 
            \end{pmatrix}
            \Rightarrow
            \begin{pmatrix}
                1 & 1 & 1 & 1 & 0 & 0 \\
                0 & 1 & 1 & -1 & 1 & 0 \\
                0 & 1 & 2 & -2 & 0 & 1 
            \end{pmatrix}
            \Rightarrow
            \begin{pmatrix}
                1 & 1 & 1 & 1 & 0 & 0 \\
                0 & 1 & 1 & -1 & 1 & 0 \\
                0 & 0 & 1 & -1 & -1 & 1 
            \end{pmatrix}
            \Rightarrow
        }_{\text{прямой ход метода Гаусса}}$$ $$\underbrace{
            \Rightarrow
            \begin{pmatrix}
                1 & 1 & 0 & 2 & 1 & -1 \\
                0 & 1 & 0 & 0 & 2 & -1 \\
                0 & 0 & 1 & -1 & -1 & 1 
            \end{pmatrix}
            \Rightarrow
            \begin{pmatrix}
                1 & 0 & 0 & 2 & -1 & 0 \\
                0 & 1 & 0 & 0 & 2 & -1 \\
                0 & 0 & 1 & -1 & -1 & 1 
            \end{pmatrix}
        }_{\text{обратный ход метода Гаусса}}$$
:::

::: problem
**Задача 5** (**Обоснование метода Гаусса**). Вроде все очевидно, но
есть одно но: почему в правой части матрицы $(A|E)$ при применении
метода Гаусса появится именно обратная матрица? Подумайте об этом на
досуге.

*Подсказка:* для обоснования этого факта вам не помешает вспомнить о
том, что вообще такое элементарные преобразования столбцов и строк
матрицы (и чему они эквивалентны).
:::

Если вы обосновали метод Гаусса, то становится очевидным следующее:
$$\left(\frac{A}{B}\right)  \xrightarrow{\text{ЭП столбцов}} \left( \frac{E}{BA^{-1}}\right)$$
$$\left(A|B\right)  \xrightarrow{\text{ЭП строк}} \left(E|A^{-1}B\right)$$

На десерт в этой главе покажу вам красивую задачу, в которой фигурирует
так называемая нильпотентная матрица - матрица, для которой существует
целое число $m$, такое что $A^m = O$ - нулевая матрица.

::: problem
**Задача 6** (15.56). Итак, доказать, что для нильпотентной матрицы
выполняется равенство:
$$E + A  + A^{2} + \dots + A^{m-1} = (E - A)^{-1}$$ Сразу говорю: даже
не думайте о формуле Тейлора. Во-первых, это не правильно, а во-вторых,
тут тема \"обратные матрицы\" , вообще-то.
:::

# Ранг матрицы

Ранг матрицы есть ни что иное, как наибольшее количество ЛНЗ строк
матрицы. Причём оказывается, что количество ЛНЗ строк равно количеству
ЛНЗ столбцов (умные дяди и тёти говорят: \"строчный ранг равен
столбцовому\"). Чтобы лучше разобраться с понятием ранга матрицы
проведём \"мостик\" к нему из предыдущей темы.

## Определение

Вы знаете, что с помощью ЭП строк можно из невырожденной квадратной
матрицы сделать единичную. Такую процедуру включает в себя метод Гаусса
нахождения обратной матрицы.

Попробуем применить такую же процедуру к *любой* матрице размера
$m\times n$, и посмотрим что получится. Будем применять ЭП строк, и
предположим, что в матрице $A$ есть $r$ линейно независимых строк.

::: obs
*Замечание 1*. Если вдруг при применении прямого хода метода Гаусса у
нас возникнет нуль на диагонали, то мы просто меняем эту строку местами
с той, у которой этот элемент не нулевой. Если таких не найдется, то
есть все элементы столбца с номером большем, чем у рассматриваемого,
равны нулю, то нужно поменять этот столбец с последним (или любым
другим, но с последним лучше, чтобы не встречаться с этим нулевым).

Ситуацию, которую я пытался описать, лучше показать на примере:
$$\begin{pmatrix}
0 & 1 & 3 \\
0 & 2 & 1
\end{pmatrix}$$ Тут у всех строк первый элемент равен нулю, и поэтому,
чтобы обеспечить ненулевой элемент на месте $a_{11}$ необходимо поменять
непутёвый первый столбец с другим.
:::

Обработав таким образом $r$ строк, мы получим матрицу вида[^2]:
$$\label{skelet}
\left(
\begin{tabular}{c|c}
    E & $\bullet$ \\
    \hline
    O & B \\
\end{tabular}
\right)$$ где $E$ - единичная матрица размера $r$.

::: problem
**Задача 7**. Жирной точкой в полученной матрице обозначена какая-то не
важная нам подматрица. Интересно другое: а что из себя представляет
матрица $B$? Определите её вид, исходя из того, что матрица $A$ имела
$r$ ЛНЗ строк.
:::

Из результата, который вы получите, очевидно, что если у матрицы есть
$r$ ЛНЗ строк, то у неё также будет и $r$ ЛНЗ столбцов. Этот факт
называют **теоремой о рангах**, а волшебное число $r = \text{rg }A$ и
называется **рангом матрицы**.

### Альтернативное определение (через базисный минор) {#альтернативное-определение-через-базисный-минор .unnumbered}

**Базисный минор** матрицы $A$ - определитель подматрицы, построенной на
пересечении $r$ ЛНЗ строк и столбцов матрицы $A$, где $r$ определяется
условием
$$\{\exists M_r \ne 0\} \wedge \{\forall M_{r+1} = 0\}\footnote{Если подматрицы размера $r+1$ вообще существуют}$$
и называется рангом матрицы $A$. Как и в прошом определении ранг нулевой
матрицы *принимается* равным нулю.

::: problem
**Задача 8**. Покажите, что базисных миноров может быть несколько
(аналогично тому, как в трёхмерном пространстве можно выбрать базис
векторов не единственным образом).
:::

::: problem
**Задача 9** (**Теорема о базисном миноре**). Покажите, что любой
базисный минор не равен нулю (используйте магию элементарных
преобразований и знания о том как при них изменяется определитель).
:::

::: lo
*Лирическое отступление 1*. Насколько я понимаю, ранг матрицы ввели для
того, чтобы не говорить \"у матрицы $r$ ЛНЗ строк/столбцов\" , тем
более, что это одно и то же число. Вместо этого удобнее сказать \"ранг
матрицы равен $r$\".
:::

## Свойства ранга матрицы

Здесь по классике - надо посмотреть как понятие ранга связано с тем, что
мы уже знаем: умножение и сложение матриц, невырожденность (для
квадратных матриц).

::: problem
**Задача 10** (**Сумма рангов и ранг суммы**). Поставьте правильный знак
($>, <, \ge, \le$) между суммой рангов и рангом суммы матриц $A$ и $B$.
Естественно, надо обосновать свой выбор. Доказать неравенство можно
путём доказательства невозможности противоположного неравенства.
:::

::: problem
**Задача 11** (**Ранг произведения**). Допустим, у вас есть какая-то
важная матрица $A$. И, вдруг, пришёл к вам Александр Николаевич, умножил
$A$ на матрицу $B$ и спрашивает: \"как изменится ранг матрицы???\". Ваши
действия?
:::

Но, как всегда, всё интересное начинается, когда мы накладываем какие-то
условия на матрицу.

::: problem
**Задача 12** (**Невырожденность**). Пусть матрица
$A \in \underset{n\times n}{M}$ (квадратная и размера $n$). Тогда
интуитивно понятно, что, если $\text{rg }A = n$, то матрица $A$
невырожденная, и наоборот. Попробуйте доказать это.
:::

Таким образом, у нас имеется связь понятий, которые мы тут придумали
вокруг матрицы $A$:
$$\fbox{rg $A = n \Leftrightarrow |A| \ne 0 \Leftrightarrow \exists A^{-1}$}$$

## Как находить ранг матрицы?

Хороший вопрос, ответ на который вы уже знаете: элементарными
преобразованиями выделяем ЛНЗ строки/столбцы и на каком-то этапе ранг
матрицы станет виден сразу. Особенно фанатичные любители линейной
алгебры могут довести матрицу $A$ до вида
[\[skelet\]](#skelet){reference-type="eqref" reference="skelet"}, и
тогда ранг будет очевиден с максимальной очевидностью.

Приведу пример нахождения ранга матрицы (ЛЗ строки просто
выбрасываются):

::: ex
**Пример 2**. $\text{rg }A = ?$ $$A = 
    \begin{pmatrix}
        2 & 4 & 2 \\
        -1 & -2 & -1 \\
        1 & 5 & 3 \\
        8 & 1 & -2 \\
        2 & 7 & 4 
    \end{pmatrix}
    \rightarrow 
    \begin{pmatrix}
        2 & 4 & 2 \\
        0 & 0 & 0 \\
        1 & 5 & 3 \\
        8 & 1 & -2 \\
        2 & 7 & 4 
    \end{pmatrix}
    \rightarrow
    \begin{pmatrix}
        2 & 4 & 2 \\
        0 & 3 & 2 \\
        0 & -15 & -10 \\
        0 & 3 & 2 
    \end{pmatrix}
    \rightarrow
    \begin{pmatrix}
        2 & 4 & 2 \\
        0 & 3 & 2 
    \end{pmatrix}$$ Ответ: rg $A = 2$
:::

Кроме ранга матрицы можно найти **базисную подсистему (БП)**[^3]
строк/столбцов. Это ни что иное, как заумное название наибольшей
совокупности ЛНЗ строк/столбцов. Чтобы их найти нужно действовать так
же, как при нахождении ранга матрицы, только при этом нужно запомнить
номера строк и столбцов, которые вы оставили при ЭП. Эти строки/столбцы
в исходной матрице и будут БП, а на пересечении БП столбцов с БП строк
располагается невырожденная подматрица порядка rg $A$.

На примере станет понятнее:

::: ex
**Пример 3**. Найти ранг матрицы $A$, указать какую либо базисную
подсистему столбцов, строк, а также невырожденную подматрицу порядка rg
$A$.

-   Совершаем ЭП *строк*: $$A = 
            \begin{pmatrix}
                0 & 0 & 2 & 1 & -1 & 2 \\
                0 & 0 & -4 & -2 & 2 & -4 \\
                3 & -6 & 5 & 1 & 2 & 5 \\
                -1 & 2 & 5 & 3 & -7 & 2 
            \end{pmatrix}
            \rightarrow
            \begin{pmatrix}
                0 & 0 & 2 & 1 & -1 & 2 \\
                0 & 0 & 20 & 10 & -19 & 11 \\
                -1 & 2 & 5 & 3 & -7 & 2 
            \end{pmatrix}
            \rightarrow$$ $$\rightarrow
            \begin{pmatrix}
                0 & 0 & 2 & 1 & -1 & 2 \\
                0 & 0 & 0 & 0 & -9 & -9 \\
                -1 & 2 & 5 & 3 & -7 & 2 
            \end{pmatrix}$$ Столбцы №1, 3, 5 можно принять за базисные
    (они ЛНЗ)[^4]\

-   Формируем подматрицу из столбцов №1, 3, 5 и совершаем ЭП *столбцов*:
    $$\tilde{A} =
            \begin{pmatrix}
                0 & 2 & -1 \\
                0 & -4 & 2 \\
                3 & 5 & 2 \\
                -1 & 5 & -7 
            \end{pmatrix}
            \rightarrow
            \begin{pmatrix}
                0 & 0 & -1 \\
                0 & 0 & 2 \\
                3 & 9 & 2 \\
                -1 & -9 & -7
            \end{pmatrix}
            \rightarrow
            \begin{pmatrix}
                0 & 0 & -1 \\
                0 & 0 & 2 \\
                3 & 0 & 2 \\
                -1 & -6 & -7
            \end{pmatrix}$$ Строки №1, 3, 4 - базисные строки А\

-   Невырожденная подматрица: $$\begin{pmatrix}
                0 & 2 & -1 \\
                3 & 5 & 2 \\
                -1 & 5 & -7
            \end{pmatrix}$$
:::

Надеюсь, десерт с прошлой недели вам понравился, потому что сейчас будет
не менее вкусно:

::: problem
**Задача 13**. Доказать:
$$\forall A, B \in \underset{n\times n}{M} \hookrightarrow \text{rg}
    \begin{pmatrix}
        A & E \\
        BA & B 
    \end{pmatrix} 
    = n$$
:::

::: problem
**Задача 14** (16.19.4). rg
$A(\omega) =\ ?\ (\forall \omega \in \mathbb{R})$ $$A =
    \begin{pmatrix}
        1 & 1 & 1 \\
        1 & \omega & \omega^{2} \\
        1 & \omega^{2} & \omega 
    \end{pmatrix}$$
:::

# Системы линейных алгебраических уравнений (СЛАУ)

Как вы решали системы уравнений в школе? Лично я пользовался правилом:
\"N уравнений, N неизвестных - значит можно решить\" , а затем тупо
исключал переменные. И на самом деле, этого вам хватит для каких-то
своих вычислений \"ручками\". Например, решить какую нибудь простую
задачку по физике. Такое правило работает для линейных уравнений вида:
$$\begin{aligned}
    \left\{
    \begin{aligned}
        a_{11}x_{1} + a_{12}x_{2} + \dots + a_{1n}x_{n} &= b_{1} \\
        a_{21}x_{1} + a_{22}x_{2} + \dots + a_{2n}x_{n} &= b_{2} \\
        \dots \dots \dots \dots \dots \dots \dots \dots  \\
        a_{n1}x_{1} + a_{n2}x_{2} + \dots + a_{nn}x_{n} &= b_{n} 
    \end{aligned} \;
    \Leftrightarrow
    \underbrace{Ax = b}_{\text{матричная форма записи}}
    \right. \\
\end{aligned}$$ относительно переменных $x_1, \dots, x_n$, если матрица
$A$ невырождена. То есть, её строки ЛНЗ[^5].

Но, конечно, ручками никто не считает, если системы уравнений огромного
порядка, относительно кучи неизвестных. Вот тогда то к нам и приходят на
помощь методы линейной алгебры. Наш старый друг Гаусс и тут приуспел, он
использовал тот самый метод, состоящий из двух \"ходов\". Эта схема
работает и в случае решения СЛАУ[^6] общего вида:

$$\left\{
    \begin{aligned}
        &a_{11}x_{1} + a_{12}x_{2} + \dots + a_{1n}x_{n} = b_{1} \\
        &a_{21}x_{1} + a_{22}x_{2} + \dots + a_{2n}x_{n} = b_{2} \\
        &\dots \dots \dots \dots \dots \dots \dots \dots  \\
        &a_{m1}x_{1} + a_{m2}x_{2} + \dots + a_{mn}x_{n} = b_{m} 
    \end{aligned}
    \right. \\
$$ Но! Прежде чем начинать решать, давайте выясним, когда вообще это
можно делать. Да-да, вопрос существования (и единственности) чего-либо
будет вас преследовать очень часто. И не зря! Будет очень грустно, если
будущий вы, молодой ученый из ЦАГИ, найдёте решение несовместной системы
уравнений, и самолёт упадёт. **Совместная** СЛАУ - у которой есть хотя
бы одно решение.

Итак, нам предстоит рассмотреть сначала вопрос совместности СЛАУ, а
затем обсудить один из методов их решения.

## Необходимые определения

Чтобы говорить на одном языке, давайте обзовём некоторые объекты, с
которыми нам предстоит работать.

Во-первых, понятно, что система уравнений полностью определяется
коэфициентами перед неизвестными, а также **свободными членами** $b_i$ в
правой части системы. Матрица, составленная из коэффициентов $a_{ij}$
называется **основной матрицей системы**: $$\underset{m \times n}{A} = 
    \begin{pmatrix}
            a_{11} & a_{12} & \cdots & a_{1n} \\
            a_{21} & a_{22} & \cdots & a_{2n} \\
            \vdots & \vdots &  & \vdots \\
            a_{m1} & a_{m2} & \cdots & a_{mn}
    \end{pmatrix}$$ **Расширенной матрицей системы** будем называть вот
это: $$\underset{m \times (n+1)}{(A|b)} = 
    \begin{pmatrix}
        a_{11} & a_{12} & \cdots & a_{1n} & b_{1}\\
        a_{21} & a_{22} & \cdots & a_{2n} & b_{2}\\
        \vdots & \vdots &  & \vdots & \vdots \\
        a_{m1} & a_{m2} & \cdots & a_{mn} & b_{m}
    \end{pmatrix}$$

Во-вторых, система может иметь не единственное решение, и в таком случае
*какое-либо* решение $x_0$ системы мы будем называть **частным
решением**[^7]. А вся совокупность решений системы (она бесконечная, как
мы увидим) называется **общим решением**.

В-третьих, свободных членов может вообще не быть, и тогда система будет
называться **однородной**.

::: {#linear-problem .problem}
**Задача 15**. Сейчас надо рассмотреть очень важный факт в линейной
алгере. Докажите, что если $x_1, \dots, x_s$ - частные решения
однородной системы, то их линейная комбинация также будет решением.
:::

От этой задачи мы переходим к понятию **фундаментальной системы решений
(ФСР)**. Вы только что доказали, что линейная комбинация решений - тоже
решение. У ленивых математиков возникает вопрос: а можно ли как-то
минимизировать количество частных решений, но чтобы при этом любое
решение системы можно было бы выразить их линейной комбинацией? Такая
совокупность решений, которые будут ЛНЗ, и называется ФСР однородной
системы. Это понятие позволит нам в общем виде записывать решения
совместных систем: если $x_0$ - частное решение неоднородной системы
(ЧРНС), а $x_1, \dots, x_s$ - ФСР соответствующей однородной системы (с
той же матрицей $A$), то её общее решение записывается в виде:
$$\label{general-solution}
x = x_0 + \sum\limits_{i=1}^{s}\lambda_{i}x_{i} = \text{ЧРНС} + \text{общее решение однородной}$$
этот факт сразу же следует из решения задачи
[15](#linear-problem){reference-type="ref" reference="linear-problem"}.

::: problem
**Задача 16**. Покажите, что ФСР можно выбрать неединственным образом.
:::

::: problem
**Задача 17**. Докажите более сильное утверждение, чем в задаче
[15](#linear-problem){reference-type="ref" reference="linear-problem"}:
$$\left\{x_{1}, \dots, x_{s} - \text{частные решения } Ax = 0 \right\} \Leftrightarrow \left\{\forall \lambda_{i} \in \mathbb{R} \hookrightarrow \sum\limits_{i=1}^{s}\lambda_{i}x_{i} - \text{частные решения } Ax = 0\right\}$$
:::

## Критерий совместности системы (т. Кронекера-Капелли)

::: problem
**Задача 18**. Докажите, что система $Ax = b$ совместна
$\Leftrightarrow \text{rg }(A|b) = \text{rg }A$. На самом деле это не
сложно, нужно только расписать: что означает совместность системы, и как
можно трактовать тот факт, что при добавлении столбца к матрице её ранг
не изменяется.
:::

## Метод Гаусса решения СЛАУ

Сначала поговорим о методе Гаусса решения СЛАУ в общем случае, а затем
рассмотрим примеры.

Если при нахождении обратной матрицы мы проводили \"ходы\" Гаусса с
матрицей $(A|E)$, то сейчас мы будем работать с расширенной матрицей
системы $(A|b)$. По сути, проводя ЭП со строками этой матрицы мы
складываем уравнения, меняем их местами и умножаем на числа, а
перестановка столбцов[^8] эквивалентна переобозначению неизвестных[^9].
Таким образом, после проведения этой процедуры мы получим матрицу (здесь
мы опять выбросили ЛЗ строки):
$$(A|b) \xrightarrow{\text{ЭП строк}} (E|R|\tilde{b}) = \begin{pmatrix}
    1 & \dots & 0 & \tilde{a}_{1 (r+1)} & \dots & \tilde{a}_{1n} & \tilde{b}_1 \\
    \vdots & & \vdots & \vdots & & \vdots & \vdots \\
    0 & \dots & 1 & \tilde{a}_{r (r+1)} & \dots & \tilde{a}_{rn} & \tilde{b}_r
\end{pmatrix}$$ где матрица $E$ размера $r =$ rg $A$, а матрица $R$
размера $r\times (n-r)$.

Теперь вспоминаем, что мы совершали действия с уравнениями, и для
простоты, давайте предположим, что мы не меняли местами столбцы. Тогда
система уравнений будет выглядеть следующим образом: $$\label{gauss-eq}
\left\{
\begin{aligned}
    &x_{1} + 0 + \dots + 0 + \tilde{a}_{1 (r+1)}x_{r+1} + \dots + \tilde{a}_{1n}x_{n} = \tilde{b}_{1} \\
    &0 + x_{2} + \dots + 0 + \tilde{a}_{2 (r+1)}x_{r+1} + \dots + \tilde{a}_{2n}x_{n} = \tilde{b}_{2} \\
    &\dots \dots \\
    &0 + 0 + \dots + x_{r} + \tilde{a}_{2 (r+1)}x_{r+1} + \dots + \tilde{a}_{rn}x_{n} = \tilde{b}_{r} 
\end{aligned}
\right.$$

Видно, что переменных больше чем уравнений. В такой ситуации есть
свобода выбора решений. Это лучше понять на примере: уравнение
$$\label{simple-ex}
x_1 + 2 x_2 = 1$$ имеет бесконечное количество решений. Можно перенести
$2x_2$ направо $$x_1 = 1 - 2 x_2$$ и тогда, задавая любое значение для
$x_2$ мы получим соответствующее значение $x_1$, и эта пара будет
удовлетворять уравнению
[\[simple-ex\]](#simple-ex){reference-type="eqref"
reference="simple-ex"}.

Точно также в системе [\[gauss-eq\]](#gauss-eq){reference-type="eqref"
reference="gauss-eq"} последние $x_{r+1}, \dots, x_{n}$ можно перенести
направо и выбирать любыми, а затем получать соответствующие значения
$x_1, \dots, x_r$.

Переменные $x_{r+1}, \dots, x_{n}$ называются **свободными**, а
$x_1, \dots, x_r$ **основными**.

Запишем решение в матричном виде. Сначала столбец основных переменных:
$$\label{main-var}
\begin{pmatrix}
    x_1 \\
    x_2 \\
    \vdots \\
    x_r
\end{pmatrix} 
=
\begin{pmatrix}
    \tilde{b}_1 \\
    \tilde{b}_2 \\
    \vdots \\
    \tilde{b}_r
\end{pmatrix}
-
\begin{pmatrix}
    \tilde{a}_{1 (r+1)} & \tilde{a}_{1 (r+2)} & \dots & \tilde{a}_{1n} \\
    \tilde{a}_{2 (r+1)} & \tilde{a}_{2 (r+2)} & \dots & \tilde{a}_{2n} \\
    \vdots & \vdots & & \vdots \\
    \tilde{a}_{r (r+1)} & \tilde{a}_{r (r+2)} & \dots & \tilde{a}_{rn}
\end{pmatrix}
\begin{pmatrix}
    \lambda_{1} \\
    \lambda_{2} \\
    \vdots \\
    \lambda_{n-r}
\end{pmatrix}$$ Здесь свободные переменные заменили параметрами
$x_{r+i} = \lambda_i \in \mathbb{R}$, где
$i = \overline{1, \dots, n-r}$.

Чтобы записать в матричном виде полное решение $x_1, \dots, x_n$,
представим столбец свободных переменных в следующем виде:
$$\label{free-var}
\begin{pmatrix}
    x_{r+1} \\
    \vdots \\
    x_n
\end{pmatrix}
= 
\begin{pmatrix}
    1 & \dots & 0 \\
    \vdots & & \vdots \\
    0 & \dots & 1 
\end{pmatrix}
\begin{pmatrix}
    \lambda_{1} \\
    \lambda_{2} \\
    \vdots \\
    \lambda_{n-r}
\end{pmatrix}$$

Объединяя выражения [\[main-var\]](#main-var){reference-type="eqref"
reference="main-var"} и [\[free-var\]](#free-var){reference-type="eqref"
reference="free-var"} получаем: $$\label{gauss-solution}
x = 
\begin{pmatrix}
    \tilde{b}  \\
    0 \\
    \vdots \\
    0
\end{pmatrix}
+
\begin{pmatrix}
    - R  \\
    E
\end{pmatrix}
\begin{pmatrix}
    \lambda_{1}  \\
    \vdots \\
    \lambda_{n-r}
\end{pmatrix}$$ Задавая различные значения
$\lambda_i \in \mathbb{R},\ i = \overline{1, \dots, n-r}$ мы получим
различные решения.

Матрица $\Phi = \begin{pmatrix}
    -R \\
    E
\end{pmatrix}$ называется **фундаментальной матрицей системы (ФМС)**.

::: problem
**Задача 19**. Покажите, что столбцы ФМС образуют ФСР однородной системы
$Ax = 0$
:::

::: problem
**Задача 20**. Покажите как нужно изменить решение
[\[gauss-solution\]](#gauss-solution){reference-type="eqref"
reference="gauss-solution"}, если мы меняли местами столбцы. Рассмотрите
простейший случай с друмя столбцами.
:::

::: ex
**Пример 4**. Никто не запрещает нам применять метод Гаусса, если есть
только основные переменные, то есть, когда матрица $A$ невырожденная.
Тогда $x = \tilde{b}$, например: $$\left\{
    \begin{aligned}
        y + 3z &= -1 \\
        2x +3y +5z &= 3 \\
        3x +5y + 7z &= 6
    \end{aligned}
    \right.
    \leftrightarrow
    \begin{pmatrix}
        0 & 1 & 3 & -1 \\
        2 & 3 & 5 & 3 \\
        3 & 5 & 7 & 6 
    \end{pmatrix}
    \rightarrow
    \begin{pmatrix}
        2 & 3 & 5 & 3 \\
        0 & 1 & 3 & -1 \\
        0 & 1 & -1 & 3 
    \end{pmatrix}
    \rightarrow$$ $$\rightarrow
    \begin{pmatrix}
        2 & 3 & 5 & 3 \\
        0 & 1 & 3 & -1 \\
        0 & 0 & 1 & -1 
    \end{pmatrix}
    \rightarrow
    \begin{pmatrix}
        2 & 3 & 0 & 8 \\
        0 & 1 & 0 & 2 \\
        0 & 0 & 1 & -1 
    \end{pmatrix}
    \rightarrow
    \begin{pmatrix}
        2 & 0 & 0 & 2 \\
        0 & 1 & 0 & 2 \\
        0 & 0 & 1 & -1 
    \end{pmatrix}
    \rightarrow
    \begin{pmatrix}
        1 & 0 & 0 & 1 \\
        0 & 1 & 0 & 2 \\
        0 & 0 & 1 & -1 
    \end{pmatrix}$$ Ответ: $x = 1;\ y = 2;\ z = -1$
:::

Приведу пример с неквадратной матрицей системы:

::: ex
**Пример 5**. $$\begin{pmatrix}
        1 & -5 & -6 & 11 & -9 \\
        5 & 1 & -4 & 3 & 7 \\
        1 & 8 & 7 & -15 & 17 
    \end{pmatrix}
    \rightarrow
    \begin{pmatrix}
        1 & -5 & -6 & 11 & -9 \\
        0 & 26 & 26 & -52 & 52 \\
        0 & 13 & 13 & -26 & 26 
    \end{pmatrix}
    \rightarrow
    \begin{pmatrix}
        1 & -5 & -6 & 11 & -9 \\
        0 & 1 & 1 & -2 & 2
    \end{pmatrix}
    \rightarrow$$ $$\rightarrow
    \begin{pmatrix}
        1 & 0 & -1 & 1 & 1 \\
        0 & 1 & 1 & -2 & 2
    \end{pmatrix}
    =
    (E|R|\tilde{b});\quad
    R =
    \begin{pmatrix}
        -1 & 1  \\
        1 & -2 
    \end{pmatrix},\
    \tilde{b} =
    \begin{pmatrix}
        1  \\
        2 
    \end{pmatrix}$$ Ответ: $$x = 
    \begin{pmatrix}
        \tilde{b}  \\
        0 \\
        \vdots \\
        0
    \end{pmatrix}
    +
    \begin{pmatrix}
        - R  \\
        E
    \end{pmatrix}
    \begin{pmatrix}
        \lambda_{1}  \\
        \vdots \\
        \lambda_{n-r}
    \end{pmatrix}
    = 
    \begin{pmatrix}
        1  \\
        2 \\
        0 \\
        0
    \end{pmatrix}
    +
    \begin{pmatrix}
        1 & -1  \\
        -1 & 2  \\
        1 & 0 \\
        0 & 1 
    \end{pmatrix}
    \begin{pmatrix}
        \lambda_{1}  \\
        \lambda_{2}
    \end{pmatrix}
    ,\quad \lambda_{1,2} \in \mathbb{R}$$
:::

::: problem
**Задача 21**. Попробуйте запрогать метод Гаусса! Учтите все \"если\" ,
которые могут быть.
:::

::: problem
**Задача 22** (**Двойственность: нахождение СЛАУ по известной ФМС**).
Есть интересный вопрос: можно ли найти СЛАУ по известной ФМС? Попробуйте
найти $A$, зная $\Phi$. Используйте тот факт, что $A\Phi = O$.
:::

# Линейное пространство

Наконец, мы дошли до самого важного момента в изучении курса \"Линейная
алгебра\". Лучше сказать - здесь и начинается линейная алгебра. Но,
прежде чем пойти дальше, нам необходимо взглянуть назад и вспомнить что
мы изучали. $$\left.
\begin{aligned}
&\text{Числа } \\
&\text{Векторы } \\
&\text{Матрицы } \\
&...
\end{aligned}
\right\}
\textbf{Что у них общего?}$$ А общее у них то, что для всех них была
определена **линейная комбинация**: если
$\boldsymbol{x}, \boldsymbol{y}$ - числа, векторы или матрицы, то при
некоторых условиях $\alpha \boldsymbol{x} + \beta \boldsymbol{y}$ - тоже
число, вектор или матрица $(\alpha ,\beta \in \mathbb{R})$. Для чисел
это работает всегда, а, например, для матриц только если
$\boldsymbol{x}$ и $\boldsymbol{y}$ имеют одинаковые размеры.

И ленивые математики сказали: \"А чего это мы будем изучать какие-то
вектора, матрицы, функции и что там ещё есть? Давайте не различать
объекты, если для них можно ввести линейную комбинацию (то есть сложение
и умножение на число), подчиняющуюся привычным правилам сложения и
умножения\".

С этого момента нам *наплевать на природу объектов* с которыми мы
работаем, нам лишь важно знать, что из них можно построить линейную
комбинацию, которая имеет такую же природу. Так рождается понятие
**линейного пространства**:

::: defin
**Def 1**. Непустое множество $\mathscr{L}$ называется линейным
пространством (ЛП)[^10], если на нем введены операции сложения и
умножения на число, подчиняющиеся аксиомам:

1.  **Аксиомы сложения:**

    -   Коммутативность:
        $\forall a, b \in \mathscr{L} \hookrightarrow a + b = b + a$

    -   Ассоциативность:
        $\forall a,b,c \in \mathscr{L} \hookrightarrow (a + b) + c = a + (b + c)$

    -   Существование нейтрального элемента относительно сложения:
        $$\exists 0 \in \mathscr{L} : \forall x \in \mathscr{L} \hookrightarrow x + 0 = 0 + x = x$$

    -   Существование противоположного элемента:
        $$\forall a \in \mathscr{L}\ \exists x \in \mathscr{L} : x + a = a + x = 0$$

2.  **Аксиомы умножения на число:**

    -   Ассоциативность:
        $\forall a \in \mathscr{L}\ \forall \lambda, \mu \in \mathbb{R} \hookrightarrow (\lambda \mu)a = \lambda(\mu a)$

    -   Существование нейтрального элемента относительно умножения на
        число:
        $$\forall a \in \mathscr{L} \hookrightarrow 1\cdot a = a, \text{ где } 1 \in \mathbb{R}$$

3.  **Общее свойство сложения и умножения на число:**
    $$\forall a,b \in \mathscr{L}\ \forall \lambda, \mu \in \mathbb{R} \hookrightarrow (\lambda + \mu)(a + b) = \lambda (a + b) + \mu (a + b) = \lambda a + \lambda b + \mu a + \mu b$$
:::

::: lo
*Лирическое отступление 2*. Ещё один аргумент, который я могу привести,
чтобы убедить вас в полезности введения ЛП: развивая математику вокруг
ЛП мы, как физики, можем применить результаты, полученные для ЛП, к
интересующему нас объекту (какой-либо физической системе), являющемуся
примером ЛП.

Например, квантовая механика использует понятие линейного пространства
для описания квантовых систем, которые не подчиняются законам
классической механики. Но там вводится не обычное ЛП: чтобы оно
моделировало реальный микромир необходимо вводить дополнительные
математические объекты и условия.

По сути, так и строятся частные случаи линейных пространств - вводится
какая-либо дополнительная структура. Типичные примеры: евклидово
пространство - это ЛП с введённым скалярным произведением, нормированное
пространство - ЛП с введённой нормой.
:::

::: problem
**Задача 23**. Для закрепления понятия ЛП предлагаю вам проверить,
является ли линейным пространством:

1.  Множество векторов, параллельных данной плоскости

2.  Множество верхнетреугольных матриц

3.  Множество многочленов степени $n$

4.  Множество многочленов степени не выше $n$

5.  Множество радиус-векторов, проведённых к любой из заданных двух
    прямых, проходящих через начало координат.

*Подсказка:* во всех случаях стоит проверить - не получится ли так, что
какая-нибудь ЛК элементов множества не будет принадлежать этому
множеству.
:::

::: obs
*Замечание 2*. Интересный факт: ЛК векторов линейного пространства по
определению состоит из конечного числа слагаемых. Почему? Чтобы избежать
некоторых тонкостей. Например, давайте рассмотрим ЛП многочленов
$\mathscr{L}$ с фиксированной степенью, но никак не ограниченной. То
есть, в этом пространстве нет рядов многочленов. Тогда нельзя составлять
ЛК с бесконечным числом элементов.

Этот запрет можно обосновать и с другой стороны, смотрите как интересно
получится:
$$1 + x + x^2/2 + \dots + x^n/n! + \dots \stackrel{\rm def}{=}e^x \notin \mathscr{L}$$
Мало того, что ряды по определению не являются элементами пространства,
так ещё из-за допущения бесконечных линейных комбинаций мы получаем
экспоненту элементом пространства $\mathscr{L}$, что не так.
:::

Далее мы познакомимся с понятиями базиса, размерности, линейной
оболочки, а также линейного подпространства и суммы подпространств.

## Базис и размерность

Раньше мы имели дело с понятием базиса только в случае геометрического
пространства. Теперь же, мы можем распространить это понятие на линейное
пространство.

::: defin
**Def 2**. Упорядоченный набор векторов
$e_1, \dots, e_n \in \mathscr{L}$ - **базис** в $\mathscr{L}$, если

1.  $e_1, \dots, e_n$ - ЛНЗ

2.  $\forall x \in \mathscr{L} \hookrightarrow x = x_1 e_1 + \dots + x_n e_n$,
    то есть, любой вектор выражается линейной комбинацией базисных.
    Числа $x_1, \dots, x_n$ - **координаты** вектора $x$ в заданном
    базисе.

Обращаю внимание, что линейная независимость здесь имеется ввиду именно
векторов ЛП. Её определение будет звучать следующим образом: система
векторов называется ЛНЗ, если только тривиальная ЛК этих векторов равна
*нулевому вектору пространства*.
:::

::: problem
**Задача 24**. Покажите, что представление вектора в виде ЛК базисных
векторов единственно. То есть, что у вектора только один набор координат
в заданном базисе.
:::

::: problem
**Задача 25**. Покажите, что если базис состоит из $n$ векторов, то его
нельзя дополнить еще одним вектором этого пространства (и получить базис
из $n+1$ вектора). Это число $n$ назвается **размерностью** линейного
пространства dim $\mathscr{L}$[^11].
:::

::: problem
**Задача 26**. Найдите размерность пространств симметричных и
антисимметричных матриц размера $n$.
:::

::: problem
**Задача 27**. Найдите размерность пространства последовательностей
Фибоначчи.
:::

::: obs
*Замечание 3*. Вспоминается другой объект, удовлетворяющий определению
базиса - ФСР однородной СЛАУ. То есть, множество решений однородных СЛАУ
образуют ЛП с базисом из ФСР.
:::

::: problem
**Задача 28**. Образует ли ЛП-во множество решений неоднородной СЛАУ?
:::

### О поиске базиса заданного пространства {#о-поиске-базиса-заданного-пространства .unnumbered}

У вас, наверняка, возникает вопрос: \"Санёк, вот есть у нас какое-то
пространство. Как найти его базис?\". Ответить на этот вопрос легче на
примере.

Рассмотрим пространство матриц размера $m\times n$. Какой можно ввести
базис? Давайте запишем типичного представителя пространства - некоторую
матрицу: $$A =
\begin{pmatrix}
    a_{11} & \cdots & a_{1n} \\
    \vdots & & \vdots \\
    a_{m1} & \cdots & a_{mn}
\end{pmatrix}$$ Далее нужно подумать, как представить эту матрицу
линейной комбинацией наипростейших. Наипростейшая матрица - нулевая, с
единицей на $ij$-м месте. Обозначим её как $E_{ij}$ Таким образом[^12]:
$$A = \sum\limits_{i=1}^{n} \sum\limits_{j=1}^{m} a_{ij} E_{ij}$$ В
полученной сумме $m\cdot n$ слагаемых, следовательно dim
$\mathscr{L} = m \cdot n$. Я хочу сказать, что универсального алгоритма
нет, есть только рекомендация: смотрите \"самого типичного
представителя\" и пытайтесь его разложить по \"наипростейшим\".

## Линейное подпространство и линейная оболочка

Давайте рассмотрим простой пример ЛП: геометрическое двумерное
пространство, в котором обитают 2D-векторы. Вы, наверное, обратили
внимание, что в нём есть еще одно ЛП. Точнее, их бесконечно много:
множество векторов параллельных заданной прямой будет также ЛП. Почему?
ЛК векторов параллельных прямой - также параллельна ей.

Можно привести другие примеры:

-   ЛП столбцов размера $n$ содержит в себе ЛП столбцов размера $n$ с
    нулевой первой координатой (к примеру).

-   ЛП матриц размера $m\times n$ содержит в себе ЛП верхнетреугольных
    матриц того же размера.

Они навевают нам идею обозвать как-нибудь эти *пространства внутри
рассматриваемых пространств*. Не долго думая, математики назвали их
**подпространствами** (ПП).

Более строго: ПП пространства $\mathscr{L}$ - это непустое подмножество
пространства $\mathscr{L}$, линейная комбинация элементов которого
является элементом этого подмножества.

::: obs
*Замечание 4*. Из определения видно, что само пространство $\mathscr{L}$
является ПП. Т.к. множество также является подмножеством себя.
:::

Пусть у нас есть какое-то пространство $\mathscr{L}$. *Как можно
задавать его ПП?* Вспоминаем определение: чтобы подмножество было ПП,
надо, чтобы ЛК любых его элементов тоже была элементом подмножества.

И тут возникает идея: давайте возьмём кучку векторов
$a_1, \dots, a_k \in \mathscr{L}$[^13], и к ним добавим все их ЛК
(гениально). Полученная кучка - множество всех ЛК набора векторов -
называется **линейной оболочкой** (ЛО) векторов $a_1, \dots, a_k$.
Обозначается и определяется ЛО векторов $a_1, \dots, a_k$ так:
$$\mathscr{L}(a_1, \dots, a_k) \stackrel{\rm def}{=}\{\lambda_1 a_1 + \dots + \lambda_k a_k\ |\ \lambda_i \in \mathbb{R}\}$$
Совершенно очевидно, что ЛО это ПП, так как по определению любой её
элемент - ЛК некоторых.

::: problem
**Задача 29**. Чем является ЛО трёх некомпланарных векторов
геометрического пространства?
:::

## Замена базиса

Базисы - они как президенты, их периодически приходится менять. В
демократических линейных пространствах для этого нужна всего одна
матрица - **матрица перехода** $S$. Она содержит информацию о
координатах старых базисных векторов в новом базисе.

Итак, пусть $\boldsymbol{e'} = (e_1', \dots, e_n')$ - новые базисные
вектора пространства $\mathscr{L}$, а без штрихов - старые. Сейчас
забудьте о том, что базисные вектора какие-то особенные - каждый из
$e_1', \dots, e_n'$, как и любой вектор пространства, выражается
линейной комбинацией старых базисных векторов:
$$e_i' = \sum\limits_{j=1}^n s_{ij}e_j$$ В матричном виде это
записывается так: $$\boldsymbol{e'} = \boldsymbol{e}S$$ Таким образом,
зная матрицу перехода $S$, можно найти новые базисные векторы,
выраженные через старые. А столбцы этой матрицы - координаты новых
базисных векторов в старом базисе.

::: problem
**Задача 30**. Пусть нам не понравился новый ~~президент~~ базис
$\boldsymbol{e'} = \boldsymbol{e}S$, и мы заменили его на другой
$\boldsymbol{e''}$ с помощью матрицы перехода $R$. Как связаны базисы
$\boldsymbol{e}$ и $\boldsymbol{e''}$?
:::

::: problem
**Задача 31**. Докажите, что матрица $S$ обратима. То есть, переходить
можно не только от $\boldsymbol{e}$ к $\boldsymbol{e'}$, но и обратно с
помощью матрицы $S^{-1}$ (используйте ЛНЗ-ть базисных векторов).
:::

::: obs
*Замечание 5*. Прежде чем перейти к следующей задаче, я хочу сделать
маленькое замечание. Координаты вектора в заданном базисе - не есть сам
вектор. Это лишь его интерпретация, которая нам понятна, если мы знаем
базисные вектора. Поэтому, я не буду писать $x = (x_1, \dots, x_n)$, так
как эта запись стирает границу между объектами \"вектор пространства\" и
\"столбец координат\".

В дальнейшем мы таки сотрём эту границу, и такое равенство мы сможем
поставить. Но, пока что, мы не эволюционировали настолько сильно, и до
знакомства с понятием изоморфизма будем ставить знак соответствия между
вектором пространства и его координатным столбцом в заданном базисе:
$$x \xleftrightarrow{\boldsymbol{e}} \xi = \begin{pmatrix}
        x_1 \\
        \vdots \\
        x_n
    \end{pmatrix}$$
:::

::: problem
**Задача 32**. Пусть в пространстве $\mathscr{L}$ задан базис
$\boldsymbol{e}$ и нам известны координаты $\xi$ вектора
$x \in \mathscr{L}$ в этом базисе. Найдите координаты $\xi'$ этого
вектора в новом базисе $\boldsymbol{e'}$. Матрица перехода $S$ от
старого базиса к новому известна.
:::

## Сумма подпространств. Проецирование вектора на подпространство

Вернёмся к примеру с 2D-пространством и векторами параллельными прямым
(из пункта про ПП). Давайте рассмотрим две несовпадающие прямые
проходящие через начало координат.

Мы знаем, что суммой векторов, параллельных этим прямым, можно получить
любой вектор 2D-пространства, причём *единственным образом*! А что, если
добавить третью прямую, не параллельную первым двум? Тогда, суммой трёх
векторов, параллельных этим прямым, можно получить любой вектор
плоскости *неоднозначно*.

Такое представление вектора пространства через сумму векторов
подпространств заслуживает своего названия. Как всегда, математики не
мудрили, и назвали (описанную мной выше) операцию получения нового ПП из
других **суммой подпространств**. Давайте дадим более аккуратное
определение в случае общего ЛП:

::: defin
**Def 3**. Пусть $\mathscr{L}$ - линейное пространство, а
$\mathscr{L}_1, \dots, \mathscr{L}_k$ - его ПП-ва.
$\tilde{\mathscr{L}}$ - сумма этих подпространств, если:
$$\tilde{\mathscr{L}} = \mathscr{L}_1 + \dots + \mathscr{L}_k \stackrel{\rm def}{=}\{x_1 + \dots + x_k\ |\ x_i \in \mathscr{L}_i,\ i = \overline{1, \dots, k} \}$$
Если
$\forall x \in \tilde{\mathscr{L}} \hookrightarrow x = x_1 + \dots + x_k$
(где $x_i \in \mathscr{L}_i$) - единственное представление вектора
$x$[^14], то сумма подпространств называется прямой. Обозначается прямая
сумма подпространств $\mathscr{L}_1$ и $\mathscr{L}_2$ как
$\mathscr{L}_1 \oplus \mathscr{L}_2$.
:::

::: obs
*Замечание 6*. На всякий случай обращу ваше внимание: сумма
подпространств - это *не объединение подпространств*. К примеру,
объединение прямых - это просто множество точек этих прямых, а их
сумма - плоскость, в которой они лежат.
:::

::: problem
**Задача 33**. Зато пересечение ПП-в - тоже ПП. Докажите это.
:::

::: problem
**Задача 34**. Является ли прямой суммой сумма ПП-в: Чётных и нечётных
функций (в пространстве функций)? Симметричных и антисимметричных матриц
(в пространстве матриц $\underset{n\times n}{M}$)?
:::

Пример с плоскостью и прямыми может породить кучу гипотез, которые я вам
предлагаю проверить. После прочтения каждой попробуйте её проверить на
этом простом примере.

Пусть $\mathscr{L}$ - ЛП, а $\mathscr{L}_i$ - его ПП-ва.

::: problem
**Задача 35**. Верно ли, что, если dim $\mathscr{L}_i = n_i$, то
$n_1 + \dots + n_k \ge \text{dim } (\mathscr{L}_1 + \dots + \mathscr{L}_k)$?
:::

::: {#criteria-sum .problem}
**Задача 36**. Пусть
$\tilde{\mathscr{L}} = \mathscr{L}_{1} + \dots + \mathscr{L}_{k}$, dim
$\mathscr{L}_{i} = n_{i}$, $\textbf{e}^{(i)}$ - базис $\mathscr{L}_{i}$.
Верно ли:
$$\{\tilde{\mathscr{L}} \text{ - прямая сумма} \}\Leftrightarrow \{\textbf{e}^{(1)}\cup \dots \cup \textbf{e}^{(k)} \text{ - базис в } \tilde{\mathscr{L}} \}\Leftrightarrow \{\text{dim } \tilde{\mathscr{L}} = n_{1} + \dots + n_{k}\}$$
:::

::: problem
**Задача 37**. Верно ли:
$$\text{dim }(\mathscr{L}_{1} + \mathscr{L}_{2}) + \text{dim }(\mathscr{L}_{1} \cap \mathscr{L}_{2}) = \text{dim } \mathscr{L}_{1} + \text{dim } \mathscr{L}_{2}$$
:::

### Проекция вектора на подпространство {#проекция-вектора-на-подпространство .unnumbered}

Привычное понятие **проекции** можно перенести и на случай ЛП:

::: defin
**Def 4**. Пусть $\mathscr{L} = \mathscr{L}_1 \oplus \mathscr{L}_2$ - ЛП
представляется прямой суммой своих ПП-в. Тогда любой вектор
$x \in \mathscr{L}$ можно представить как сумму:
$$x = x_1 + x_2, \quad x_1 \in \mathscr{L}_1,\ x_2 \in \mathscr{L}_2$$ и
говорят, что $x_1$ - проекция вектора $x$ на подпространство
$\mathscr{L}_1$ вдоль подпространства $\mathscr{L}_2$. Аналогично для
$x_2$.
:::

::: obs
*Замечание 7*. Конечно, проекцию можно вводить и для случая прямой суммы
нескольких ПП-в. Но зачем, если можно выбрать одно (на которое будем
проецировать), а все остальные собрать во второе.
:::

::: ex
**Пример 6**. Найти проекцию вектора
$x \in \mathscr{L} = \underset{3\times 1}{M}$ на $\mathscr{L}_1$ вдоль
$\mathscr{L}_2$: $$x = \begin{pmatrix}
        2 \\
        0 \\
        -1
    \end{pmatrix}, \quad 
    \mathscr{L}_1 = \mathscr{L}\left(
    \begin{pmatrix}
        4 \\
        3 \\
        1
    \end{pmatrix},
    \begin{pmatrix}
        1 \\
        2 \\
        3 
    \end{pmatrix},
    \begin{pmatrix}
        3 \\
        1 \\
        -2
    \end{pmatrix}
    \right),\quad
    \mathscr{L}_2 = \mathscr{L}\left(\begin{pmatrix}
        1 \\
        1 \\
        1
    \end{pmatrix}\right)$$ В задании предполагается, что сумма
$\mathscr{L}_1$ и $\mathscr{L}_2$ прямая. Поэтому справедливо
утверждение задачи [36](#criteria-sum){reference-type="ref"
reference="criteria-sum"}, то есть, в обоих ПП можно выбрать базисы, и
их объединение будет базисом в прямой сумме ПП-в. Понятно, что прямая
сумма - пространство столбцов длины 3, а там как раз сидит $x$. Затем,
мы можем разложить $x$ по получившемуся базису. Чтобы найти искомую
проекцию, из разложения $x$ необходимо выбросить слагаемые из ПП вдоль
которого проецируем.

Теперь по порядку:

-   Ищем базис в заданные ПП-вах: $$\mathscr{L}_1 = \mathscr{L}\left(
        \begin{pmatrix}
            4 \\
            3 \\
            1
        \end{pmatrix},
        \begin{pmatrix}
            1 \\
            2 \\
            3 
        \end{pmatrix},
        \begin{pmatrix}
            3 \\
            1 \\
            -2
        \end{pmatrix}
        \right) = \mathscr{L}\left(
        \begin{pmatrix}
            4 \\
            3 \\
            1
        \end{pmatrix},
        \begin{pmatrix}
            1 \\
            2 \\
            3 
        \end{pmatrix},
        \begin{pmatrix}
            4 \\
            3 \\
            1
        \end{pmatrix}
        \right)
        = \mathscr{L}\left(
        \underbrace{\begin{pmatrix}
                4 \\
                3 \\
                1
            \end{pmatrix},
            \begin{pmatrix}
                1 \\
                2 \\
                3 
        \end{pmatrix}}_{\text{базис}}
        ,
        \begin{pmatrix}
            0 \\
            0 \\
            0
        \end{pmatrix}
        \right)$$

-   Раскладываем $x$ по базисным векторам $$x = \begin{pmatrix}
            2 \\
            0 \\
            -1
        \end{pmatrix} = \underbrace{ \lambda_1 \begin{pmatrix}
            4 \\
            3 \\
            1
        \end{pmatrix} + \lambda_2 \begin{pmatrix}
            1 \\
            2 \\
            3
    \end{pmatrix}}_{x_1} + \underbrace{\lambda_3 \begin{pmatrix}
    1 \\
    1 \\
    1
    \end{pmatrix}}_{x_2}, \quad
        x_1 \in \mathscr{L}_1,\ x_2 \in \mathscr{L}_2$$ Получили СЛАУ!
    Она не такая большая, и решение, в принципе, можно угадать. Если не
    угадывается, то используйте метод Гаусса, а я просто напишу решение:
    $$\lambda = \begin{pmatrix}
            \lambda_1 \\
            \lambda_2 \\
            \lambda_3
        \end{pmatrix} = 
        \begin{pmatrix}
        -1 \\
        -3 \\
        9
        \end{pmatrix} \Rightarrow \textbf{Ответ: } x_1 = \begin{pmatrix}
        -7 \\
        -9 \\
        -10
    \end{pmatrix}$$

::: obs
*Замечание 8*. Нам не пришлось искать базис в ПП, вдоль которого
проецировали, так как оно было задано ЛО единственного вектора, который
взяли базисным. Также хочу заметить, что не нужно пытаться найти
\"красивый\" базис[^15]. Примите его таким, какой он есть![^16] Если,
конечно, вы уверены, что это базис.
:::
:::

## Summary

Итак, посмотрим на изученное с высоты птичьего полёта. ЛП - это любое
множество, линейная комбинация элементов (векторов) которого - элемент
этого множества. Среди этих векторов неоднозначно можно найти базис -
упорядоченную и полную систему ЛНЗ векторов. Количество базисных
векторов - размерность ЛП. Если базис не нравится его можно заменить с
помощью матрицы перехода. Внутри ЛП можно найти другие ЛП, которые по
отношению к нему называются подпространствами. Задавать ПП данного
пространства можно с помощью линейной оболочки (множество всех ЛК)
какого-либо набора его векторов. ПП-ва можно \"суммировать\" и получать
новые.

Поляну накрыли, далее нам нужно узнать какой движ мы можем на ней
устроить.

# Линейное отображение (ЛО)

Линейные пространства сами по себе хороши, но людям этого мало. Нам
нехватает статики, нужна динамика: ЛП, описывающее какую либо физическую
систему постоянно эволюционирует. Это непрерывный процесс, но пока что,
для простоты, мы будем рассматривать мгновенные изменения пространств,
которые описываются **отображениями**.

Вы уже знакомы с понятием отображения множества $A$ на множество $B$.
Это правило, по которому каждому элементу множества $A$ сопоставляется
элемент или множество элементов из $B$. Это очень общее определение, и
интерес вызывает его частный случай, который продолжает нашу идеологию
линейности:

::: defin
**Def 5**. Пусть $\mathscr{L}_1,\ \mathscr{L}_2$ - ЛП-ва. Отображение
$\varphi:\ \mathscr{L}_1 \rightarrow \mathscr{L}_2$ называется линейным,
если[^17]:

-   Единственность
    образа:$$\forall x \in \mathscr{L}_1\ \exists!\ y = \varphi (x) \in \mathscr{L}_2$$

-   Образ ЛК = ЛК образов:
    $$\varphi(\lambda x + \mu y) = \lambda \cdot \varphi(x) + \mu \cdot \varphi(y) \quad \forall x,y \in \mathscr{L}_1,\ \forall \lambda, \mu \in \mathbb{R}$$

Замечу, что в этом определении не сказано, что в пространстве
$\mathscr{L}_2$ всем элементам сопоставлены элементы из $\mathscr{L}_1$.

С другой стороны, множество векторов
$\varphi(\mathscr{L}_1) = \{y \in \mathscr{L}_2\ | \ \exists x \in \mathscr{L}_1:\ y = \varphi(x)\}$
образует ПП, которое называется **образом отображения** $\varphi$ и
обозначается Im $\varphi$.
:::

::: problem
**Задача 38**. Докажите, что Im $\varphi$ - ПП пространства
$\mathscr{L}_2$.
:::

Помимо образа ЛО, нам будет нужно оперировать с множеством векторов,
имеющих образом нулевой. Поэтому введём определение:

::: defin
**Def 6**. Множество векторов $x \in \mathscr{L}_1$, образы которых
равны нулевому вектору, называется **ядром** отображения $\varphi$ и
обозначается Ker $\varphi$.
:::

Вам будет проще понимать всю кухню с отображениями пространств, если
представлять такую картинку:

![image](limage1.jpg)

::: problem
**Задача 39**. Докажите, что $\varphi(0) = 0 \in \mathscr{L}_2$.
:::

::: problem
**Задача 40**. Докажите, что Ker $\varphi$ - ПП пространства
$\mathscr{L}_1$.
:::

## Свойства линейных отображений

Мы ввели понятие линейности отображения, образа и ядра. Теперь давайте
свяжем разрозненные понятия, которые мы придумали вокруг ЛП и ЛО[^18].

В первую очередь, нам нужно восстановить историческую справедливость:
вспомнить забытые понятия инъективности[^19] и сюрьективности[^20]
отображений, и связать их с нашими новыми конструкциями Im $\varphi$ и
Ker $\varphi$.

::: problem
**Задача 41** (**ЛО и его тип**). Как истинные физики, давайте проверим
крайние случаи. Каким будет отображение, у которого ядро нулевое
(сюрьективным или инъективным)? Каким будет отображение, у которого Im
$\varphi = \mathscr{L}_2$? Справедливы ли обратные утверждения? То есть,
если отображение сюрьективно/инъективно, будет ли у него ядро нулевое?
:::

Во-вторых, давайте вспомним атрибуты линейных пространств. У них есть
размерность, подпространства, задаваемые линейной оболочкой. Какой-либо
набор их векторов может быть ЛЗ или ЛНЗ.

::: {#LT-LS .problem}
**Задача 42** (**ЛО и атрибуты ЛП**). Пусть
$\varphi:\ \mathscr{L}_1 \rightarrow \mathscr{L}_2$.

-   Если вектора $x_1, \dots, x_k$ ЛЗ/ЛНЗ, то какие будут вектора
    $\varphi(x_1), \dots, \varphi(x_k)$?

-   Пусть $\mathscr{L}$ - ПП пространства $\mathscr{L}_1$. Кажется
    интуитивно верным утверждение:
    $$\mathscr{L} = \mathscr{L}(a_1,\dots, a_k) \Rightarrow \varphi (\mathscr{L}) = \mathscr{L}(\varphi(a_1), \dots, \varphi(a_k))$$

-   Также ясно, что размерность пространства не должна увеличиться:
    $$\text{dim } \mathscr{L} \ge \text{dim } \varphi (\mathscr{L}) = \text{dim Im } \varphi$$

Докажите последние два утверждения.
:::

::: problem
**Задача 43** (**Инъективное ЛО и атрибуты ЛП**). Что изменится в задаче
[42](#LT-LS){reference-type="ref" reference="LT-LS"}, если ЛО будет
инъективным? (сюрьективное не интересно, его всегда можно получить
просто выкинув ненужные вектора из $\mathscr{L}_2$)
:::

::: obs
*Замечание 9* (**Пространство линейных отображений**). Линейные
отображения умные математики называют гомоморфизмами, а множество всех
линейных отображений пространства $\mathscr{L}_1$ на $\mathscr{L}_2$
обозначают Hom$(\mathscr{L}_1,\mathscr{L}_2)$. Если положить по
определению
$$\forall \varphi, \psi \in \text{Hom}(\mathscr{L}_1,\mathscr{L}_2) \hookrightarrow
    (\varphi + \psi)(x) \stackrel{def}{=} \varphi(x) + \psi(x)\qquad 
    (\lambda \varphi)(x) \stackrel{def}{=} \lambda \varphi(x)$$ То
видно, что Hom$(\mathscr{L}_1,\mathscr{L}_2)$ - линейное
пространство\...
:::

## Конструирование линейных отображений

На данный момент мы уже хорошо осознаём фундаментальность понятия базиса
ЛП. Если мы знаем базис - мы знаем пространство. И возникает вопрос:
если мы сопоставим *базисным* векторам $e_1, \dots, e_n$ пространства
$\mathscr{L}_1$ *какие-то* вектора $c_1, \dots, c_n$ пространства
$\mathscr{L}_2$, то определяет ли это *однозначно* ЛО
$\varphi:\ \mathscr{L}_1 \rightarrow \mathscr{L}_2$ такое, что
$\varphi(e_i) = c_i,\ i = \overline{1, \dots, n}$? Что значит
определяет? Значит, что при таком условии *любому* вектору
$x \in \mathscr{L}_1$ мы можем сопоставить его образ из $\mathscr{L}_2$.

Вопрос тривиальный - да: $\forall x \in \mathscr{L}_1$ можно представить
линейной комбинацией базисных. В результате действия на него отображения
получим[^21]: $$\label{image-coord-1}
\varphi(x) = \varphi(e_1)\xi^1 + \dots + \varphi(e_n)\xi^n = c_1 \xi^1 + \dots + c_n \xi^n$$
Таким образом, зная образы базисных векторов, мы можем найти образ
любого вектора (благодаря линейности).

::: obs
*Замечание 10*. Подчеркну ещё раз - набор $c_1,\dots, c_n$ произвольный.
:::

## Матрица линейного отображения

Вернёмся к ситуации из прошлого пункта. Если в $\mathscr{L}_2$ завести
базис $\boldsymbol{f} = (f_1, \dots, f_m)$, то набор векторов
$c_1, \dots, c_n$ можно по нему разложить: $$\label{image-coord-2}
c_j = \alpha^1_j f_1 + \dots + \alpha^m_j f_m, \quad j = \overline{1, \dots, n}$$
А также, по нему можно разложить образ $\forall x \in \mathscr{L}_1$:
$$\label{image-coord-3}
    \varphi(x) = \eta^1 f_1 + \dots + \eta^m f_m$$ Сравнивая
[\[image-coord-3\]](#image-coord-3){reference-type="eqref"
reference="image-coord-3"} и
[\[image-coord-1\]](#image-coord-1){reference-type="eqref"
reference="image-coord-1"} с учётом
[\[image-coord-2\]](#image-coord-2){reference-type="eqref"
reference="image-coord-2"} имеем[^22]:
$$\eta^i = \sum\limits_{j=1}^n \alpha_j^i \xi^j \Leftrightarrow \eta = A \xi$$
Эта формула позволяет найти координатный столбец $\varphi(x)$, если
известны координаты $x$. Матрица
$\underset{m\times n}{A} = \alpha_j^i,\ i = \overline{1, \dots, m},\ j = \overline{1, \dots, n}$
называется **матрицей линейного отображения**
$\varphi: \mathscr{L}_1 \rightarrow \mathscr{L}_2$ в базисах
$\boldsymbol{e} = (e_1, \dots, e_n)$ и
$\boldsymbol{f} = (f_1, \dots, f_m)$. Чтобы сообщать об этом коротко
пишут: $$\varphi \xleftrightarrow{\boldsymbol{e},\ \boldsymbol{f}\ } A$$

::: obs
*Замечание 11*. Смысл этой матрицы очевиден из
[\[image-coord-2\]](#image-coord-2){reference-type="eqref"
reference="image-coord-2"}: j-ый её столбец - это координатный столбец
$\varphi(e_j)$ в базисе $f_1,\dots, f_m$.
:::

Какая главная характеристика любой матрицы? Ранг! А главные
характеристики ЛО это инъективность и сюрьективность. Давайте найдём
связь между ними:

::: problem
**Задача 44**. Пусть ЛО инъективно/сюрьективно, тогда чему равен ранг
его матрицы $A$? Работает ли это в обратную сторону?
:::

Так как матрицу ЛО мы определяли для конкретных базисов пространств
$\mathscr{L}_{1,2}$, то при замене хотя бы одного из них изменится и
матрица $A$.

::: problem
**Задача 45**. Пусть $\boldsymbol{e} \xrightarrow{S} \boldsymbol{e}'$ и
$\boldsymbol{f} \xrightarrow{P} \boldsymbol{f}'$, где
$\boldsymbol{e}, \boldsymbol{e}'$ - базисы в $\mathscr{L}_1$, а
$\boldsymbol{f}, \boldsymbol{f}'$ - базисы в $\mathscr{L}_2$. Как
изменится матрица $A$ линейного отображения $\varphi$?
$$\varphi: \mathscr{L}_1 \rightarrow \mathscr{L}_2 \qquad \varphi \xleftrightarrow{\boldsymbol{e},\boldsymbol{f}} A$$
:::

::: obs
*Замечание 12*. Если в пространствах $\mathscr{L}_{1,2}$ заданы базисы
**e** и **f**, то мы можем получить любое линейное отображение с помощью
указания образов базисных векторов (см. прошлый пункт), а их координаты
в базисе **f** составляют матрицу $A$.

Возникает вопрос: а если мы от фонаря возьмём какую-либо матрицу
$A \in \underset{m \times n}{M}$, то будет ли она матрицей какого-либо
ЛО? Конечно! Мы просто выберем базисы **e** и **f** в пространствах
$\mathscr{L}_{1}^n$ и $\mathscr{L}_{2}^m$, а затем построим ЛО с помощью
матрицы $A$ и равенства
[\[image-coord-2\]](#image-coord-2){reference-type="eqref"
reference="image-coord-2"}.
:::

## Изоморфизм

Как я уже говорил, интересности начинаются когда мы снабжаем объекты
рассмотрения (будь то ЛП или ЛО) определёнными свойствами. Естественно,
заданными свойствами будут обладать не все объекты.

К примеру: объект - множество всех линейных отображений пространства
$\mathscr{L}_1$ на $\mathscr{L}_2$. Если мы накладываем условие
инъективности, то неинъективные отображения исключаются из этого
множества, оно становится беднее ~~чем россияне~~. Зато при работе с
оставшимися мы получаем определённые плюшки (из задач первого пункта).

Продолжим это увлекательное занятие и наложим ~~санкции на РФ~~ условие:
пусть размерности пространств $\mathscr{L}_1$ и $\mathscr{L}_2$
совпадают. Тогда возникает вопрос:

::: problem
**Задача 46**. Можно ли построить биективное[^23] отображение
$\varphi: \mathscr{L}_1 \rightarrow \mathscr{L}_2$? Оказывается, что
можно. Докажите это, используя рассуждения из пункта \"Конструирование
линейных отображений\".
:::

Из биективности $\varphi: \mathscr{L}_1 \rightarrow \mathscr{L}_2$
следует, что существует **обратное отображение** $\varphi^{-1}$.

::: defin
**Def 7**. $\varphi^{-1}: \mathscr{L}_2 \rightarrow \mathscr{L}_1$ -
отображение обратное к
$\varphi: \mathscr{L}_1 \rightarrow \mathscr{L}_2$, если
$$\forall y = \varphi (x) \in \mathscr{L}_2 \hookrightarrow \varphi^{-1}(y) = x \in \mathscr{L}_1$$
:::

Напомню, что биективным (как и сюрьективным или инъективным) может быть
любое отображение, не обязательно линейное. Биективное линейное
отображение принято называть **изоморфизмом**, а пространства, между
которыми можно построить изоморфизм - **изоморфными**
$\mathscr{L}_1 \cong \mathscr{L}_2$.

::: problem
**Задача 47**. Мы получили, что если dim $\mathscr{L}_1 =$ dim
$\mathscr{L}_2$, то они изоморфные. А верно ли обратное утверждение?
Опять оказывается, что да. Докажите это.
:::

Таким образом, мы имеем критерий изоморфности:
$$\fbox{$\mathscr{L}_1 \cong \mathscr{L}_2 \Leftrightarrow \text{dim } \mathscr{L}_1 = \text{dim }\mathscr{L}_2$}$$
Прелесть этого утверждения в том, что мы можем теперь \"не
различать\" пространства одной размерности в смысле линейности: ЛК
соответствующих векторов будет давать соответствующие векторы. А
построить изоморфизм можно, сопоставив базисные векторы пространств.

::: ex
**Пример 7**. Теперь мы можем выбрать удобное ЛП и работать только с
ним. Очевидным кандидатом является пространство столбцов высоты $n$.
Стандартный базис в нём: $$\begin{pmatrix}
        1 \\
        0 \\
        \vdots \\
        0
    \end{pmatrix}, \begin{pmatrix}
        0 \\
        1 \\
        \vdots \\
        0
    \end{pmatrix}, \dots, \begin{pmatrix}
        0 \\
        0 \\
        \vdots \\
        1
    \end{pmatrix}$$ Изоморфизм любого ЛП размерности $n$ с пространством
столбцов высоты $n$ называется координатным изоморфизмом. И теперь, если
вектор $x \in \mathscr{L}$ имеет координаты $(x_1, \dots, x_n)$ в базисе
$\boldsymbol{e} = (e_1, \dots, e_n)$, то мы можем написать
$x = (x_1, \dots, x_n)$, имея ввиду, что мы сопоставляем
$\boldsymbol{e}$ со стандартным базисом пространства столбцов.
:::

::: ex
**Пример 8**. Из рассуждений прошлого пункта
Hom$(\mathscr{L}^n, \mathscr{L}^m) \cong \underset{m\times n}{M}$.
:::

## Линейные преобразования

Нас, как физиков, будет интересовать не любое ЛО, а конкретный его
пример - **линейное преобразование**. Именно преобразованиями
описываются изменения физических систем (например, фазового пространства
механической системы). Далеко не все они линейные, но это уже другой
вопрос. Давайте на данном этапе сосредоточимся на линейных.

::: defin
**Def 8**. Линейное преобразование $\varphi$ пространства
$\mathscr{L}$ - линейное отображение
$\varphi: \mathscr{L} \rightarrow \mathscr{L}$ этого пространства самого
на себя.

Линейные преобразования конструируются, как и любые другие отображения,
только базисы выбираются не в двух разных пространствах, а в одном.
:::

Пусть в $\mathscr{L}$ задан базис $\boldsymbol{e}$, а в $\mathscr{L}'$
базис $\boldsymbol{e}'$. Размерности пространств совпадают и равны $n$.
Если построить изоморфизм
$\varphi: \mathscr{L}' \rightarrow \mathscr{L}$, то
$\varphi(e'_1), \dots, \varphi(e'_n)$ будут базисными для пространства
$\mathscr{L}$.

Это значит, что отображение
$$\varphi: \mathscr{L}' \rightarrow \mathscr{L}$$ которое задаётся в
конкретных базисах $\boldsymbol{e},\boldsymbol{e}'$ пространств
$\mathscr{L}$ и $\mathscr{L}'$, можно рассматривать как *преобразование*
пространства $\mathscr{L}$ (или $\mathscr{L}'$, если угодно):
$$\varphi: \mathscr{L} \rightarrow \mathscr{L}$$ в базисах
$\boldsymbol{e}, \varphi(\boldsymbol{e}')$. Теперь нам вообще не нужно
второе пространство, мы можем забыть про его существование и
переобозначить базисы пространства $\mathscr{L}$:
$$\boldsymbol{e} \rightarrow \boldsymbol{e},\ \varphi(\boldsymbol{e}') \rightarrow \boldsymbol{e}'$$
[Подводя итог нашим рассуждениям:]{.underline} линейное преобразование
пространства $\mathscr{L}$ - это линейное отображение его самого на
себя, а в силу изоморфности, мы можем рассматривать любое ЛО пространств
одинаковой размерности, как линейное преобразование любого ЛП той же
размерности.

::: problem
**Задача 48**. Составьте матрицу следующих линейных преобразований:

-   Проекции геометрического 3D пространства на плоскость $xOy$ внутри
    него.

-   Вращения на угол $\varphi$ геометрического 3D пространства вокруг
    прямой с направляющим вектором $\boldsymbol{n} = (1, 0, 1)$,
    проходящей через точку $(1, 0, 1)$
:::

::: problem
**Задача 49**. **Операции над линейными преобразованиями**

-   Определим произведение преобразований
    $(\varphi \psi)(x) = \varphi(\psi(x))$. Чему равна матрица
    преобразования $(\varphi \psi)(x)$, если
    $\varphi \xleftrightarrow{\boldsymbol{e},\boldsymbol{e}'} A,\ \psi \xleftrightarrow{\boldsymbol{e},\boldsymbol{e}'} B$?

-   Можно извратиться ещё больше, и ввести многочлен преобразований!
    $$p_n(\varphi)(x) = a_n \varphi^n(x) + \dots + a_1 \varphi(x) + a_0 \text{Id}(x)$$
    где
    $\varphi^n = \underbrace{\varphi \cdot \ldots \cdot \varphi}_{\text{n штук}}$,
    а Id$(x) = x$ - тождественное преобразование. Найдите матрицу
    преобразования $p_n(\varphi)$, если
    $\varphi \xleftrightarrow{\boldsymbol{e},\boldsymbol{e}'} A$.
:::

## Summary

# Инвариантные подпространства

Начиная с этой главы и далее мы будем рассматривать только линейные
преобразования.

[^1]: Если вдруг при применении прямого хода метода Гаусса у нас
    возникнет нуль на диагонали, то мы просто меняем эту строку местами
    с той, у которой этот элемент не нулевой.

[^2]: Если эту матрицу умножить слева на обратную к матрице ЭП строк
    (при условии, что мы не меняли столбцы местами), которые мы
    проделали, то получим исходную матрицу $A$. Представление $A$ в виде
    такого произведения называется **скелетным разложением** матрицы.

[^3]: Она может быть найдена не единственным образом! Вы это уже
    доказали ранее в задаче 2.2

[^4]: А можно столбцы № 2, 4, 6, и несколько других вариантов. Наглядное
    подтверждение неединственности выбора базисной подсистемы.

[^5]: Для интересующихся: такое-же правило справедливо и для нелинейных
    уравнений общего вида
    $\boldsymbol{F}(\boldsymbol{x}) = \boldsymbol{0}$, если функции,
    составляющее вектор-функцию $\boldsymbol{F}(\boldsymbol{x})$
    являются **независимыми**. Функциональную независимость вы изучите
    позже в курсе матана. В физике функциональная независимость обычно
    очевидна: если уравнения имеют \"разную природу\" , то они
    независимы. Например, система из ЗСЭ, ЗСИ и ЗСМ в механике для
    задачи столкновения шариков

[^6]: Почему алгебраических? Потому, что есть еще дифференциальные\...

[^7]: Для случая единственного решения просто нет необходимости вводить
    частное решение. Там решение одно, и не нужно его отличать от
    совокупности других решений.

[^8]: За исключением последнего, который мы ни с кем не меняем!

[^9]: Например, при перестановке первого и второго столбцов нам
    необходимо в столбце неизвестных поменять местами первую и вторую.
    Это не сложно понять, рассмотрите матричную запись СЛАУ и вспомните
    как умножаются матрицы.

[^10]: Точнее, это определение линейного пространства над полем
    действительных чисел. В случае $\lambda, \mu \in \mathbb{C}$ - над
    полем комплексных чисел. Часто линейное пространство называют
    векторным, а его элементы векторами.

[^11]: От слова dimension. Часто пишут размерность пространства вместе с
    его обозначением: $\mathscr{L}^n$

[^12]: Конечно, это не единственный вариант выбора базиса, можно выбрать
    другие базисные матрицы

[^13]: $k$ может быть и больше размерности пространства $\mathscr{L}$,
    мы его никак не ограничиваем. То есть, ЛО может быть построена и на
    ЛЗ векторах.

[^14]: как в примере с двумя прямыми

[^15]: Я про ситуацию, когда хочется сделать столбцы единичными. Иногда
    такое не получится в принципе: (1 0 13/5) и (0 1 0).

[^16]: Чтобы поддержать diversity общества столбцов, и сэкономить своё
    время.

[^17]: Первое условие можно опустить, если по умолчанию считать, что
    образ любого вектора единственен

[^18]: Во всех задачах не стесняйтесь пользоваться свойством линейности
    отображения.

[^19]: $\varphi$ инъективно, если
    $\forall x_1 \ne x_2 \hookrightarrow \varphi(x_1) \ne \varphi(x_2)$.

[^20]: $\varphi$ сюрьективно, если
    $\forall y \in \mathscr{L}_2\ \exists x \in \mathscr{L}_1:\ \varphi(x) = y$

[^21]: Единственность $\varphi$ доказывается не сложно от противного:
    пусть $\exists \psi: \psi(e_i) = c_i$ и $\varphi(x) \ne \psi(x)$,
    тогда\...

[^22]: Для тех кому не очевидно: мы приравниваем выражения для
    $\varphi(x)$ из
    [\[image-coord-1\]](#image-coord-1){reference-type="eqref"
    reference="image-coord-1"} и
    [\[image-coord-3\]](#image-coord-3){reference-type="eqref"
    reference="image-coord-3"}, затем переносим все слагаемые в одну
    сторону и получаем *ЛК базисных векторов* $f_i$ с коэффициентами
    $\eta^i - \sum\limits_{j=1}^n \alpha_j^i \xi^j$, *которая равна
    нулю*. Только тривиальная ЛК базисных векторов равна нулю,
    следовательно $\eta^i = \sum\limits_{j=1}^n \alpha_j^i \xi^j$

[^23]: $\varphi$ биективно, когда оно инъективно и сюрьективно
